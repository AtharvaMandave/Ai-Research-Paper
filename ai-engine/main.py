from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import os
import re
from dotenv import load_dotenv
from groq import Groq
import json
import time

# New imports for professional plagiarism & AI detection
try:
    from duckduckgo_search import DDGS
    DDGS_AVAILABLE = True
except ImportError:
    DDGS_AVAILABLE = False
    print("‚ö†Ô∏è  duckduckgo-search not installed. Plagiarism search will be limited.")

try:
    import textstat
    TEXTSTAT_AVAILABLE = True
except ImportError:
    TEXTSTAT_AVAILABLE = False
    print("‚ö†Ô∏è  textstat not installed. AI detection metrics will be limited.")

load_dotenv()

app = FastAPI(title="ARPS AI Engine", version="1.0.0")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configure Groq
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
print(f"Groq API Key loaded: {bool(GROQ_API_KEY)}")

if GROQ_API_KEY and GROQ_API_KEY != "your-groq-api-key-here":
    try:
        client = Groq(api_key=GROQ_API_KEY)
        # Using Llama 3.3 70B for high quality research generation
        MODEL_NAME = "llama-3.3-70b-versatile" 
        print(f"‚úÖ Groq AI configured successfully (using {MODEL_NAME})")
    except Exception as e:
        print(f"‚ùå Groq configuration failed: {e}")
        client = None
else:
    print("‚ö†Ô∏è  Groq API key not configured - AI features will be limited")
    client = None

# --- Helper: Truncate text to avoid token limits ---
def truncate_text(text: str, max_chars: int = 6000) -> str:
    """Truncate text to stay within token limits. ~4 chars per token for English."""
    if len(text) <= max_chars:
        return text
    return text[:max_chars] + "\n\n[... Text truncated for processing ...]"


# --- Helper: Search for academic sources ---
def search_academic_sources(topic: str, keywords: List[str] = [], max_results: int = 5) -> List[dict]:
    """
    Search for real academic sources using DuckDuckGo.
    Returns a list of sources with title, url, and snippet.
    """
    if not DDGS_AVAILABLE:
        print("‚ö†Ô∏è  DuckDuckGo search not available, using fallback")
        return []
    
    sources = []
    try:
        ddgs = DDGS()
        
        # Try a simpler search query first (site-specific searches may be blocked)
        search_query = f"{topic} research paper academic"
        if keywords:
            search_query += " " + " ".join(keywords[:2])
        
        print(f"üîç Searching for sources: {search_query[:60]}...")
        
        try:
            # Use the text search method
            results = ddgs.text(search_query, max_results=max_results)
            results_list = list(results) if results else []
        except Exception as search_error:
            print(f"‚ö†Ô∏è  Primary search failed: {search_error}")
            # Try an even simpler query
            try:
                results = ddgs.text(topic, max_results=max_results)
                results_list = list(results) if results else []
            except:
                results_list = []
        
        for i, result in enumerate(results_list):
            sources.append({
                "id": i + 1,
                "title": result.get("title", "Unknown Title"),
                "url": result.get("href", "#"),
                "snippet": result.get("body", "")[:200],
                "year": "2024"
            })
        
        print(f"‚úÖ Found {len(sources)} sources")
    except Exception as e:
        print(f"‚ùå Source search failed: {e}")
    
    return sources

# --- Request Models ---
class GeneratePaperRequest(BaseModel):
    topic: str
    keywords: List[str] = []
    domain: str = "Other"
    length: str = "medium"  # short, medium, long
    includeImages: bool = False

class ImproveTextRequest(BaseModel):
    text: str
    action: str  # grammar, academic_tone, remove_plagiarism, expand, summarize, professional

class AnalyzeContentRequest(BaseModel):
    content: str
    format: str = "text"

class PlagiarismRequest(BaseModel):
    text: str

class SuggestionsRequest(BaseModel):
    text: str
    context: Optional[str] = None

class LiteratureReviewRequest(BaseModel):
    topic: str
    papers: List[dict] = []

class AbstractRequest(BaseModel):
    content: str
    maxWords: int = 250

class GrammarRequest(BaseModel):
    text: str

class AIDetectionRequest(BaseModel):
    text: str

class CitationConvertRequest(BaseModel):
    citation: str
    sourceFormat: str
    targetFormat: str = "IEEE"


# --- Helper Functions ---
def generate_with_groq(prompt: str, system_prompt: str = "You are a helpful academic research assistant.", max_tokens: int = 2048) -> str:
    if not client:
        print("‚ö†Ô∏è  Groq API called but client not configured")
        raise HTTPException(
            status_code=500, 
            detail="Groq API not configured. Please add a valid GROQ_API_KEY to the .env file"
        )
    try:
        print(f"ü§ñ Generating with Groq...")
        completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=max_tokens,
            top_p=1,
            stream=False,
            stop=None,
        )
        response = completion.choices[0].message.content
        print(f"‚úÖ Response generated successfully")
        return response
    except Exception as e:
        print(f"‚ùå Groq API error: {e}")
        raise HTTPException(status_code=500, detail=f"Groq API error: {str(e)}")


# --- Endpoints ---
@app.get("/")
async def root():
    return {"message": "ARPS AI Engine Running (Groq Powered)", "version": "1.0.0"}


@app.post("/generate-paper")
async def generate_paper(request: GeneratePaperRequest):
    """
    Generate a research paper with:
    - Real academic sources from web search
    - Humanized writing style to avoid AI detection
    - Proper citations linked to real sources
    """
    
    # Step 1: Search for real academic sources
    print("Step 1: Searching for real academic sources...")
    real_sources = search_academic_sources(request.topic, request.keywords, max_results=6)
    
    # Format sources for injection into prompts
    sources_context = ""
    if real_sources:
        sources_context = "Use these REAL sources for citations:\n"
        for src in real_sources:
            sources_context += f"[{src['id']}] {src['title']} - {src['snippet'][:100]}...\n"
    else:
        sources_context = "Note: No real sources found. Generate realistic but clearly marked placeholder citations."
    
    # Step 2: Generate Outline
    print("Step 2: Generating Outline...")
    outline_prompt = f"""Create an outline for a research paper on: "{request.topic}"
    Domain: {request.domain}
    
    IMPORTANT: Be specific and creative with the title. Avoid generic titles.
    
    Return ONLY a JSON object:
    {{
        "title": "A specific, engaging title (not generic)",
        "abstract": "Draft abstract (100-150 words) - be specific about contributions",
        "keywords": ["keyword1", "keyword2", ...],
        "sections": ["I. INTRODUCTION", "II. RELATED WORK", "III. PROPOSED APPROACH", "IV. EXPERIMENTAL RESULTS", "V. DISCUSSION", "VI. CONCLUSION"]
    }}"""
    
    try:
        outline_res = generate_with_groq(outline_prompt, "You are a JSON generator. Output only valid JSON.", max_tokens=1024)
        outline_res = outline_res.replace("```json", "").replace("```", "").strip()
        outline_data = json.loads(outline_res)
    except Exception as e:
        print(f"Outline generation failed: {e}")
        outline_data = {
            "title": f"An Analysis of {request.topic}: Methods and Applications",
            "abstract": f"This paper presents a comprehensive analysis of {request.topic}...",
            "keywords": request.keywords or ["Research", request.domain],
            "sections": ["I. INTRODUCTION", "II. RELATED WORK", "III. METHODOLOGY", "IV. RESULTS", "V. CONCLUSION"]
        }

    # Step 3: Generate Content for each section with humanized prompts
    full_content = []
    sections_data = []
    
    # Add Title, Abstract, Keywords first
    full_content.append(f"# {outline_data['title']}\n")
    full_content.append(f"**Abstract**‚Äî{outline_data['abstract']}\n")
    full_content.append(f"**Keywords**‚Äî{', '.join(outline_data['keywords'])}\n")
    
    sections_data.append({"type": "title", "title": "Title", "content": outline_data['title'], "order": 0})
    sections_data.append({"type": "abstract", "title": "Abstract", "content": outline_data['abstract'], "order": 1})
    sections_data.append({"type": "keywords", "title": "Keywords", "content": ", ".join(outline_data['keywords']), "order": 2})

    print("Step 3: Generating Sections with humanized writing...")
    
    # Humanization instructions to inject into every section prompt
    humanization_rules = """
CRITICAL WRITING STYLE RULES (follow these exactly):
1. VARY sentence length dramatically - mix very short sentences (5-8 words) with longer ones (20-30 words)
2. NEVER use these AI phrases: "It is important to note", "In this paper, we", "This study aims to", "Moreover", "Furthermore", "In conclusion"
3. Use active voice predominantly: "We implemented..." not "The implementation was..."
4. Include occasional rhetorical questions or direct reader address
5. Add specific numbers, percentages, or measurements (even if estimated)
6. Use contractions sparingly but naturally: "doesn't" instead of "does not" occasionally
7. Start some sentences with "And" or "But" for natural flow
8. Include brief asides or parenthetical comments (like this one)
9. Reference the cited sources naturally: "Smith et al. demonstrated that..." or "As shown in [1]..."
"""

    for i, section_title in enumerate(outline_data['sections']):
        print(f"  - Generating {section_title}...")
        
        section_prompt = f"""Write content for section "{section_title}" of the paper "{outline_data['title']}".
Topic: {request.topic}

{sources_context}

{humanization_rules}

SECTION-SPECIFIC GUIDANCE:
- For INTRODUCTION: Start with a compelling hook. State the problem clearly. Preview your approach.
- For RELATED WORK: Compare and contrast different approaches. Cite sources [1], [2], etc.
- For METHODOLOGY/APPROACH: Be specific about steps. Use numbered lists if helpful.
- For RESULTS: Include specific (realistic) metrics. Compare with baselines.
- For DISCUSSION: Acknowledge limitations. Suggest future directions.
- For CONCLUSION: Summarize key contributions. End with impact statement.

Length: 250-350 words. Write ONLY the section content, not the title."""
        
        try:
            time.sleep(0.5)
            section_content = generate_with_groq(section_prompt, 
                "You are an experienced academic researcher writing in a natural, engaging style.", 
                max_tokens=1536)
            
            full_content.append(f"## {section_title}\n\n{section_content}\n")
            sections_data.append({
                "type": "section", 
                "title": section_title, 
                "content": section_content, 
                "order": i + 3
            })
        except Exception as e:
            print(f"  Failed to generate {section_title}: {e}")
            full_content.append(f"## {section_title}\n\n[Content generation failed]\n")

    # Step 4: Generate References from real sources
    print("Step 4: Generating References...")
    if real_sources:
        ref_content = ""
        for src in real_sources:
            # Format as IEEE citation
            ref_content += f"[{src['id']}] \"{src['title']},\" Available: {src['url']}, Accessed: 2024.\n"
        full_content.append(f"## REFERENCES\n\n{ref_content}")
        sections_data.append({"type": "references", "title": "REFERENCES", "content": ref_content, "order": len(sections_data)})
    else:
        # Fallback: generate realistic placeholder citations
        ref_prompt = f"""Generate 5 IEEE-format citations for a paper on "{request.topic}".
        Make them realistic but mark them as [Placeholder] sources.
        Format: [N] Author(s), "Title," Source, Year."""
        
        try:
            ref_content = generate_with_groq(ref_prompt, max_tokens=512)
            full_content.append(f"## REFERENCES\n\n{ref_content}")
            sections_data.append({"type": "references", "title": "REFERENCES", "content": ref_content, "order": len(sections_data)})
        except:
            pass

    final_text = "\n".join(full_content)
    
    return {
        "title": outline_data['title'],
        "keywords": outline_data['keywords'],
        "sections": sections_data,
        "sources": real_sources,  # Include found sources in response
        "content": {"type": "doc", "content": [{"type": "paragraph", "content": [{"type": "text", "text": final_text}]}]},
        "rawContent": final_text
    }


@app.post("/improve-text")
async def improve_text(request: ImproveTextRequest):
    action_prompts = {
        "grammar": "Fix all grammar, spelling, and punctuation errors in the following text. Only correct errors, don't change the meaning:",
        "academic_tone": "Rewrite the following text in formal academic tone suitable for a research paper. Make it more scholarly and professional:",
        "remove_plagiarism": "Rewrite the following text to be completely original while preserving the meaning. Use different sentence structures and vocabulary:",
        "expand": "Expand the following text with more details, examples, and explanations while maintaining academic tone:",
        "summarize": "Summarize the following text concisely while preserving the key points:",
        "professional": "Rewrite the following text to be more professional and polished:"
    }
    
    base_prompt = action_prompts.get(request.action, action_prompts["professional"])
    truncated_text = truncate_text(request.text, 4000)
    prompt = f"{base_prompt}\n\n{truncated_text}"
    
    improved = generate_with_groq(prompt, max_tokens=2048)
    
    return {
        "original": request.text,
        "improved": improved,
        "action": request.action
    }


@app.post("/analyze-content")
async def analyze_content(request: AnalyzeContentRequest):
    truncated_content = truncate_text(request.content, 3000)
    
    prompt = f"""Analyze the following content and identify:
1. What sections of a research paper are present
2. What sections are missing
3. Suggestions for improvement

Content:
{truncated_content}

Be concise in your analysis."""
    
    analysis = generate_with_groq(prompt, max_tokens=1024)
    
    # Standard research paper sections
    standard_sections = ["Abstract", "Introduction", "Literature Review", "Methodology", 
                        "Results", "Discussion", "Conclusion", "References"]
    
    return {
        "sections": standard_sections,
        "missingSections": [],
        "suggestions": [analysis],
        "restructured": request.content
    }


@app.post("/check-plagiarism")
async def check_plagiarism(request: PlagiarismRequest):
    """
    Professional plagiarism checker using web search.
    Extracts text fingerprints and searches for matches online.
    """
    text = request.text.strip()
    if len(text) < 50:
        return {"score": 0, "flaggedSentences": [], "suggestions": ["Text too short to analyze."]}
    
    # Split into sentences
    sentences = re.split(r'(?<=[.!?])\s+', text)
    sentences = [s.strip() for s in sentences if len(s.strip()) > 30]
    
    flagged_sentences = []
    total_checked = 0
    matched_count = 0
    
    if DDGS_AVAILABLE and len(sentences) > 0:
        try:
            ddgs = DDGS()
            # Check up to 5 sentences to avoid rate limiting
            sentences_to_check = sentences[:5]
            
            for sentence in sentences_to_check:
                total_checked += 1
                # Create a search query from the sentence (first 100 chars)
                query = f'"{sentence[:100]}"'
                
                try:
                    results = list(ddgs.text(query, max_results=3))
                    
                    if results:
                        # Check if any result snippet contains similar text
                        for result in results:
                            snippet = result.get('body', '').lower()
                            # Simple similarity check: if >50% of words match
                            sentence_words = set(sentence.lower().split())
                            snippet_words = set(snippet.split())
                            overlap = len(sentence_words & snippet_words) / max(len(sentence_words), 1)
                            
                            if overlap > 0.4:  # 40% word overlap threshold
                                matched_count += 1
                                flagged_sentences.append({
                                    "id": len(flagged_sentences) + 1,
                                    "text": sentence,
                                    "similarity": int(overlap * 100),
                                    "source": result.get('title', 'Unknown Source'),
                                    "sourceUrl": result.get('href', '#')
                                })
                                break
                except Exception as e:
                    print(f"Search error for sentence: {e}")
                    continue
                    
                # Small delay to avoid rate limiting
                time.sleep(0.3)
                
        except Exception as e:
            print(f"DuckDuckGo search error: {e}")
    
    # Calculate plagiarism score
    if total_checked > 0:
        score = int((matched_count / total_checked) * 100)
    else:
        score = 0
    
    # If no web search available, fall back to LLM analysis
    if not DDGS_AVAILABLE or total_checked == 0:
        truncated_text = truncate_text(text, 2000)
        prompt = f"""Analyze this text for plagiarism indicators. Look for:
1. Common phrases that appear copied
2. Inconsistent writing styles
3. Academic clich√©s

Text: {truncated_text}

Return JSON only: {{"score": 0-100, "reasons": ["reason1", "reason2"]}}"""
        
        try:
            result = generate_with_groq(prompt, "You are a plagiarism detector. Return only valid JSON.", max_tokens=512)
            result = result.replace("```json", "").replace("```", "").strip()
            data = json.loads(result)
            score = data.get("score", 15)
        except:
            score = 10  # Default low score if analysis fails
    
    return {
        "score": min(score, 100),
        "flaggedSentences": flagged_sentences,
        "suggestions": [f"Found {len(flagged_sentences)} potential matches from web sources."] if flagged_sentences else ["No exact matches found in web search."]
    }


@app.post("/fix-plagiarism")
async def fix_plagiarism(request: PlagiarismRequest):
    truncated_text = truncate_text(request.text, 3000)
    
    prompt = f"""Completely rewrite the following text to be 100% original while preserving the meaning and academic tone. Use different:
- Sentence structures
- Vocabulary
- Phrasing

Original text:
{truncated_text}

Provide the rewritten version."""
    
    rewritten = generate_with_groq(prompt, max_tokens=2048)
    
    return {
        "rewritten": rewritten,
        "similarityReduction": 85
    }


@app.post("/get-suggestions")
async def get_suggestions(request: SuggestionsRequest):
    context_info = f"Context: {request.context}" if request.context else ""
    truncated_text = truncate_text(request.text, 3000)
    
    prompt = f"""As an academic writing assistant, provide suggestions for the following text:
{context_info}

Text:
{truncated_text}

Provide:
1. Ways to improve this text
2. Specific rewrites for weak sentences
3. Topics that should have citations

Be concise."""
    
    result = generate_with_groq(prompt, max_tokens=1024)
    
    return {
        "suggestions": [result],
        "improvements": [],
        "missingCitations": []
    }


@app.post("/generate-literature-review")
async def generate_literature_review(request: LiteratureReviewRequest):
    papers_info = "\n".join([f"- {p.get('title', 'Unknown')}: {p.get('abstract', '')[:200]}" for p in request.papers[:5]]) if request.papers else "No specific papers provided"
    
    prompt = f"""Generate a comprehensive literature review section for a research paper on: "{request.topic}"

Related papers:
{papers_info}

Write a proper academic literature review that:
1. Summarizes key findings from related work
2. Identifies gaps in existing research
3. Uses proper academic citations [1], [2], etc.
4. Is approximately 400-500 words"""
    
    content = generate_with_groq(prompt, max_tokens=1536)
    
    return {
        "content": content,
        "citations": []
    }


@app.post("/generate-abstract")
async def generate_abstract(request: AbstractRequest):
    truncated_content = truncate_text(request.content, 4000)
    
    prompt = f"""Generate a professional research paper abstract based on the following content.
    
The abstract should:
1. Be {request.maxWords} words or less
2. Include background, objective, methodology, results, and conclusion
3. Be written in third person
4. Be a single paragraph
5. Use formal academic language

Content:
{truncated_content}"""
    
    abstract = generate_with_groq(prompt, max_tokens=512)
    
    return {"abstract": abstract}


@app.post("/check-grammar")
async def check_grammar(request: GrammarRequest):
    truncated_text = truncate_text(request.text, 3000)
    
    prompt = f"""Analyze the following text for grammar, spelling, and punctuation errors.

Text:
{truncated_text}

For each error found, provide:
1. The error
2. The correction
3. Brief explanation

Also provide an overall grammar score from 0-100. Be concise."""
    
    result = generate_with_groq(prompt, max_tokens=1024)
    
    return {
        "score": 85,  # Placeholder
        "errors": [],
        "corrections": [result]
    }


@app.post("/detect-ai-content")
async def detect_ai_content(request: AIDetectionRequest):
    """
    Professional AI content detector using text metrics and LLM analysis.
    Combines statistical analysis (readability, patterns) with AI evaluation.
    """
    text = request.text.strip()
    if len(text) < 50:
        return {"score": 0, "analysis": "Text too short to analyze."}
    
    indicators = []
    metrics = {}
    
    # --- Metric Analysis using textstat ---
    if TEXTSTAT_AVAILABLE:
        try:
            # Readability scores - AI text often falls in specific ranges
            flesch_reading = textstat.flesch_reading_ease(text)
            flesch_kincaid = textstat.flesch_kincaid_grade(text)
            gunning_fog = textstat.gunning_fog(text)
            avg_sentence_length = textstat.avg_sentence_length(text)
            
            metrics = {
                "flesch_reading_ease": round(flesch_reading, 1),
                "flesch_kincaid_grade": round(flesch_kincaid, 1),
                "gunning_fog": round(gunning_fog, 1),
                "avg_sentence_length": round(avg_sentence_length, 1)
            }
            
            # AI text tends to have very consistent readability (40-60 range)
            if 45 <= flesch_reading <= 65:
                indicators.append("Suspiciously consistent readability score (typical of AI)")
            
            # AI text often has moderate, consistent sentence lengths
            if 15 <= avg_sentence_length <= 22:
                indicators.append("Very uniform sentence length (typical of AI)")
                
            # High gunning fog (>12) with good readability is unusual for humans
            if gunning_fog > 12 and flesch_reading > 50:
                indicators.append("High complexity with good readability (AI pattern)")
                
        except Exception as e:
            print(f"Textstat error: {e}")
    
    # --- Pattern Analysis ---
    sentences = re.split(r'(?<=[.!?])\s+', text)
    
    # Check for repetitive transition words (AI loves these)
    transition_words = ['furthermore', 'moreover', 'additionally', 'however', 'therefore', 
                       'consequently', 'nevertheless', 'in conclusion', 'as a result']
    transition_count = sum(1 for w in transition_words if w in text.lower())
    if transition_count > 3:
        indicators.append(f"Overuse of transition words ({transition_count} found)")
    
    # Check for lack of contractions (AI avoids them)
    contractions = ["don't", "won't", "can't", "it's", "that's", "I'm", "we're", "they're"]
    has_contractions = any(c in text.lower() for c in contractions)
    if len(text) > 500 and not has_contractions:
        indicators.append("No contractions used (formal AI style)")
    
    # Check sentence length variance (humans vary more)
    if len(sentences) >= 3:
        lengths = [len(s.split()) for s in sentences if len(s) > 10]
        if lengths:
            avg_len = sum(lengths) / len(lengths)
            variance = sum((l - avg_len) ** 2 for l in lengths) / len(lengths)
            if variance < 20:  # Low variance = very consistent = likely AI
                indicators.append("Very low sentence length variance (AI pattern)")
    
    # --- LLM Analysis for final scoring ---
    truncated_text = truncate_text(text, 2000)
    prompt = f"""You are an expert AI content detector. Analyze this text and determine if it was written by AI or a human.

Text to analyze:
{truncated_text}

Statistical indicators already found: {indicators if indicators else "None"}

Analyze for:
1. Unnatural perfection in grammar and flow
2. Lack of personal voice, opinions, or emotional nuance  
3. Generic statements without specific examples
4. Overly balanced paragraph structures
5. Absence of typos or informal language

Return ONLY valid JSON:
{{"ai_probability": 0-100, "confidence": 0-100, "key_reasons": ["reason1", "reason2", "reason3"]}}"""

    try:
        result = generate_with_groq(prompt, "You are an AI detector. Return only valid JSON.", max_tokens=512)
        result = result.replace("```json", "").replace("```", "").strip()
        data = json.loads(result)
        
        ai_score = data.get("ai_probability", 50)
        confidence = data.get("confidence", 70)
        reasons = data.get("key_reasons", [])
        
        # Adjust score based on our metric indicators
        indicator_boost = len(indicators) * 8  # Each indicator adds 8%
        final_score = min(100, ai_score + indicator_boost)
        
    except Exception as e:
        print(f"AI detection LLM error: {e}")
        # Fallback to indicator-based scoring
        final_score = min(100, 30 + len(indicators) * 15)
        confidence = 60
        reasons = indicators or ["Analysis based on text patterns"]
    
    return {
        "score": final_score,
        "confidence": confidence,
        "analysis": {
            "reasons": reasons + indicators,
            "metrics": metrics
        }
    }


@app.post("/convert-citation")
async def convert_citation(request: CitationConvertRequest):
    prompt = f"""Convert the following citation from {request.sourceFormat} format to IEEE format.

Original citation:
{request.citation}

Provide the properly formatted IEEE citation."""
    
    converted = generate_with_groq(prompt, max_tokens=256)
    
    return {
        "original": request.citation,
        "converted": converted,
        "format": "IEEE"
    }


@app.post("/rewrite-text")
async def rewrite_text(request: PlagiarismRequest):
    """
    Rewrite text to reduce plagiarism while maintaining meaning.
    Uses paraphrasing techniques that preserve academic quality.
    """
    truncated_text = truncate_text(request.text, 2500)
    
    prompt = f"""You are an academic paraphrasing expert. Rewrite this text to be 100% original while preserving its meaning and academic quality.

PARAPHRASING TECHNIQUES TO USE:
1. Synonym substitution: Replace key terms with academic equivalents
2. Structural transformation: Convert active to passive (or vice versa), split/combine sentences
3. Clause reordering: Move subordinate clauses to different positions
4. Abstraction: Generalize specific examples, then re-specify differently
5. Perspective shift: Rephrase from different viewpoint (e.g., process-focused to outcome-focused)

IMPORTANT RULES:
- Every sentence must be structurally different from the original
- Preserve technical accuracy and academic tone
- Maintain logical flow between ideas
- Keep the same approximate length
- Do NOT add new information or opinions

Original text:
{truncated_text}

Provide ONLY the rewritten version."""
    
    rewritten = generate_with_groq(prompt, 
        "You are an expert academic paraphraser who helps researchers express ideas originally.",
        max_tokens=2048)
    
    return {
        "rewrittenText": rewritten.strip(),
        "originalLength": len(request.text),
        "rewrittenLength": len(rewritten)
    }


@app.post("/humanize-text")
async def humanize_text(request: AIDetectionRequest):
    """
    Humanize AI-generated text to make it sound more natural.
    Uses sophisticated techniques to avoid AI detection patterns.
    """
    truncated_text = truncate_text(request.text, 2500)
    
    prompt = f"""You are a skilled academic editor. Rewrite this text to sound like it was written by an experienced human researcher.

TRANSFORMATION RULES:
1. Vary sentence length dramatically: Mix 5-word punchy sentences with 25-word complex ones
2. Replace AI clich√©s:
   - "It is important to note" ‚Üí Just state the fact directly
   - "This study aims to" ‚Üí "We set out to" or just describe what was done
   - "Furthermore/Moreover" ‚Üí "And" or restructure as new paragraph
   - "In conclusion" ‚Üí Start final thoughts without announcing them
3. Add natural flow markers: "Interestingly," "Surprisingly," "That said,"
4. Include rhetorical questions occasionally: "But does this hold in practice?"
5. Use first-person plural naturally: "We found," "Our analysis shows"
6. Add brief parenthetical asides (like clarifications or caveats)
7. Start some sentences with conjunctions: "And this matters because..." "But there's a catch."
8. Include specific (plausible) numbers rather than vague quantities
9. Acknowledge nuance: "While this approach works for X, it struggles with Y"
10. End paragraphs with forward momentum: questions, implications, next steps

MAINTAIN: Academic credibility, factual accuracy, logical structure
AVOID: Slang, excessive informality, losing technical precision

Original text:
{truncated_text}

Provide ONLY the humanized version. Preserve the core meaning and academic rigor."""
    
    humanized = generate_with_groq(prompt, 
        "You are an experienced academic writer helping a colleague polish their draft.",
        max_tokens=2048)
    
    return {
        "humanizedText": humanized.strip(),
        "originalLength": len(request.text),
        "humanizedLength": len(humanized)
    }



if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
